# ğŸ›¡ï¸ Real-Time Content Moderation System

![Project Status](https://img.shields.io/badge/status-in%20development-yellow)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

An intelligent NLP-powered content moderation system that automatically detects and flags toxic content in real-time using state-of-the-art transformer models and serverless cloud architecture.

---

## ğŸ“‹ Problem Statement

Online platforms face a critical challenge: **millions of user-generated comments are posted daily**, making manual moderation impossible to scale. Toxic contentâ€”including harassment, hate speech, and threatsâ€”damages user experience, creates legal liability, and drives users away from platforms.

**Traditional solutions fall short:**
- Manual moderation is slow, expensive, and doesn't scale
- Simple keyword filtering misses context and generates false positives
- Delayed moderation allows harmful content to spread

**This system provides:**
- Real-time automated detection of toxic content
- Context-aware classification using deep learning
- Scalable serverless architecture that handles traffic spikes
- Cost-efficient pay-per-use model suitable for platforms of any size

---

## âœ¨ Key Features

- **Multi-Category Toxicity Detection**: Identifies toxic, obscene, threatening, insulting, and hate speech content
- **Real-Time Processing**: Sub-second inference time using serverless architecture
- **Transformer-Based NLP**: Leverages pre-trained BERT models fine-tuned on toxicity datasets
- **RESTful API**: Easy integration with existing platforms via FastAPI
- **Automated Logging**: Tracks all predictions in DynamoDB for monitoring and improvement
- **Cloud-Native**: Built on AWS serverless infrastructure (Lambda, S3, DynamoDB)
- **Scalable**: Auto-scales to handle thousands of concurrent requests

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚  (HTTP/1.1) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway    â”‚
â”‚   (HTTP API)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS Lambda     â”‚â—€â”€â”€â”€â”€â”€â”‚     ECR      â”‚
â”‚ (Docker Image)  â”‚      â”‚(Image Repo)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Load Model
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Amazon S3     â”‚      â”‚   DynamoDB   â”‚
â”‚ (Model Storage) â”‚      â”‚ (Predictions)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flow:**
1. User sends HTTP request to API Gateway
2. API Gateway proxies request to Lambda
3. Lambda (running Docker container) processes request
4. Model loaded from S3 (cached in /tmp)
5. Prediction logged to DynamoDB
6. Result returned to user (toxic/clean + confidence scores)

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|-----------|---------|
| **Python 3.8+** | Core programming language for ML and API development |
| **Transformers (Hugging Face)** | Access to pre-trained NLP models (DistilBERT) for transfer learning |
| **FastAPI** | High-performance API framework with automatic documentation |
| **AWS Lambda** | Serverless compute running Docker containers for inference |
| **Amazon ECR** | Container registry for storing Docker images |
| **Amazon API Gateway** | HTTP API endpoint for public access |
| **Amazon S3** | Cloud storage for datasets, trained models, and artifacts |
| **Amazon DynamoDB** | NoSQL database for logging predictions and monitoring |
| **PyTorch** | Deep learning framework for model training and inference |
| **Pandas & NumPy** | Data manipulation and preprocessing |
| **Scikit-learn** | Model evaluation metrics and utilities |

---

## ğŸ“Š Dataset

**Primary Dataset**: [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

- **Size**: 159,571 Wikipedia comments
- **Labels**: Multi-label classification across 6 categories
  - Toxic
  - Severe Toxic
  - Obscene
  - Threat
  - Insult
  - Identity Hate
- **Challenge**: Highly imbalanced dataset with only ~10% toxic samples

---

## ğŸš€ Setup Instructions

### Prerequisites
- Python 3.8 or higher
- AWS Account (Free Tier eligible)
- Git

### Local Development Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/content-moderation-system.git
cd content-moderation-system
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download dataset**
- Visit [Kaggle Competition](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)
- Download `train.csv`, `test.csv`, `test_labels.csv`
- Place in `data/` folder

5. **Run exploratory data analysis**
```bash
jupyter notebook notebooks/01_eda_toxic_comments.ipynb
```


### AWS Deployment
Detailed instructions for deploying the infrastructure to AWS using Docker and Terraform can be found in the [Deployment Guide](DEPLOYMENT.md).

---

## ğŸ’» Usage

### API Example (After Deployment)

**Endpoint**: `POST /moderate`

**Request**:
```json
{
  "text": "Your comment text here"
}
```

**Response**:
```json
{
  "text": "Your comment text here",
  "predictions": {
    "toxic": 0.92,
    "severe_toxic": 0.15,
    "obscene": 0.78,
    "threat": 0.05,
    "insult": 0.65,
    "identity_hate": 0.12
  },
  "is_toxic": true,
  "timestamp": "2025-12-06T10:30:00Z"
}
```

---

## ğŸ“ˆ Project Status

### âœ… Completed
- [x] Project initialization and repository setup
- [x] Folder structure and version control
- [x] Exploratory Data Analysis (EDA)
- [x] Data preprocessing pipeline
- [x] Model selection and fine-tuning
- [x] Terraform template creation
- [x] FastAPI development 

### ğŸš§ In Progress
- [x] AWS Lambda deployment (Docker-based)
- [x] DynamoDB integration
- [ ] Testing and evaluation

### ğŸ”® Future Enhancements
- [ ] Multi-language support
- [ ] Real-time dashboard for monitoring
- [ ] A/B testing framework for model versions
- [ ] User feedback loop for model improvement
- [ ] Explainability features (highlight toxic phrases)
- [ ] Rate limiting and authentication
- [ ] Model versioning and rollback capability

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¤ Author

**Aravind S**
- GitHub: (https://github.com/Arv-ind-s)
- LinkedIn: [https://www.linkedin.com/in/97aravind-s/](https://www.linkedin.com/in/97aravind-s/)
- Email: arvindsathyan@gmail.com

---

## ğŸ™ Acknowledgments

- Jigsaw/Conversation AI for the toxic comment dataset
- Hugging Face for transformer models and libraries
- AWS for cloud infrastructure

---

**â­ If you find this project helpful, please consider giving it a star!**
